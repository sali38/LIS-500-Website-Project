<!-- tm_emotions.html -->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Emotion Classifier ‚Äì LIS 500 Project 3</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="style.css">

  <!-- Teachable Machine / TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
</head>

<body>
  <!-- HEADER -->
  <header class="site-header">
    <nav class="navbar container">
      <ul class="navigation">
        <li><a href="index.html">Home</a></li>
        <li><a href="tech_heroes.html">Tech Heroes</a></li>
        <li><a href="resources.html">Resources</a></li>
        <li><a href="tm_emotions.html" aria-current="page" class="active">Emotion ML Demo</a></li>
        <li><a href="about_us.html">About Us</a></li>
      </ul>
    </nav>
  </header>


  <!-- MAIN CONTENT -->
  <main class="container page-content">
    <article class="card">

      <h1 class="page-title">Emotion Classifier ‚Äì Teachable Machine</h1>
      <p>
        This page demonstrates a <strong>webcam-based emotion classifier</strong> trained with Google 
        Teachable Machine. It detects three facial expressions: 
        <b>Happy ¬∑ Sad ¬∑ Angry.</b><br>
        No images or recordings are saved‚Äîeverything runs <strong>locally in your browser</strong>.
      </p>

      <!-- Open Model Button -->
      <div class="center-block" style="margin-top:16px;">
        <a class="hero-btn"
           href="https://teachablemachine.withgoogle.com/models/Bn6RjZdcH/"
           target="_blank" rel="noopener">
          Open Our Teachable Machine Model
        </a>
      </div>

      <!-- HOW TO USE -->
      <section>
        <h2>Try the Demo</h2>
        <p>Click Start, allow camera access, and watch the prediction update in real time!</p>

        <div class="center-block" style="margin:18px 0;">
          <button id="startButton">Start Webcam &amp; Model</button>
          <button id="stopButton">Stop</button>
        </div>

        <div class="center-block">
          <video id="webcam" width="320" height="240" autoplay playsinline
            style="border-radius:10px;border:1px solid #ddd;background:#000;"></video>

          <p style="margin-top:10px;">
            <strong>Prediction:</strong> <span id="predictionLabel">waiting‚Ä¶</span>
          </p>
        </div>

        <p class="source" style="margin-top:12px;">
          *Runs entirely client-side with TensorFlow.js ‚Äî no data sent to a server.
        </p>
      </section>


      <!-- WHY EMOTIONS -->
      <section>
        <h2>Why Emotions? Connecting to Our Tech Heroes</h2>
        <p>
          Emotion recognition tools already appear in workplaces, classrooms, 
          and surveillance systems. Our Tech Heroes helped us think critically about this:
        </p>

        <ul>
          <li><strong>Ifeoma Ozoma</strong> reminds us that workers need protection against retaliation and unfair scoring.</li>
          <li><strong>Dorothy Vaughan</strong> shows that algorithms mirror the humans who build them ‚Äî not neutral by default.</li>
          <li><strong>Jamie Gong</strong> challenges us to ask whether tech can support care rather than control.</li>
        </ul>
      </section>


      <!-- HOW WE TRAINED -->
      <section>
        <h2>How We Trained the Model</h2>
        <ul>
          <li><strong>Three classes:</strong> happy, sad, angry</li>
          <li>Training data from <strong>all members</strong> (diversity reduces bias)</li>
          <li>Different lighting/backgrounds to improve generalization</li>
          <li>Realistic expressions rather than exaggerated cartoon emotions</li>
        </ul>
        <p>Videos ‚Üí image frames ‚Üí TensorFlow.js model export ‚Üí integrated into webpage.</p>
      </section>


      <!-- üî• Project Statement FULL TEXT -->
      <section>
        <h2>Project Statement</h2>

        <details open>
        <summary style="cursor:pointer;font-weight:600;">Click to expand / collapse full project statement</summary>
        <div style="margin-top:14px; line-height:1.65;">

<p>For our team, we were able to take away several lessons from computer scientist and AI researcher Dr. Joy Buolawmini‚Äôs book Unmasking AI. Such lessons have allowed us to better create our final project, so that we can avoid past mistakes and create an outcome that is equitable for all, not just for some.</p>

<p>This being said, each of us will share a few lessons that have resonated with us from Dr. Buolawmini‚Äôs book.</p>

<p><strong>For Samira</strong>, a lesson that resonated the most is that technology, especially in regard to artificial intelligence facial recognition, is that these systems are never neutral. It is no coincidence that racism and biases just appears, for example, in the mis-gendering of prominent Civil Rights activist Sojourner Truth through the usage of said facial recognition. This goes much deeper than just a simple misidentification of a historical figure. What Truth and so many others have accomplished and have endured just to be misgendered and/or misidentified by technology that is programmed by humans and thus should know how to properly identify notable figures evidently shows such non-neutral technologies.</p>

<p><strong>Yunji</strong> included the lesson of the fight to maintain privacy to one‚Äôs biometric information, specifically in regard to one‚Äôs home government and governments around the world. Nation‚Äôs governments have the job to protect its citizens in more ways than one, especially when one‚Äôs information is threatened to be stolen. Along with this, not only should governments around the world be protecting its citizens digitally from harm, but said governments should also be holding those looking to cause harm responsible. To ensure this occurs, we must continue to demand local, state, and the federal government to protect our rights so everyone‚Äôs information is safe and secure.</p>

<p><strong>And for Ellah</strong>, similarly to Samira‚Äôs, the idea that AI facial recognition was only able to correctly identify those with light skin really stood out to her. Not only was this action clearly troubling, but something that is even more frightening is that companies want to continue to move forward with facial recognition technologies like in Dr. Buolawmini‚Äôs ‚ÄúDream Mirror Project,‚Äù despite clear evidence of racial biases present, specifically in regard to those with dark skin. This being said, it is not only crucial for those who are joining the tech industry to work to dismantle racism and racial biases within the industry, but also to stand up to the already existing companies that enforce products with embedded racism and racial biases.</p>

<p>After reading Unmasking AI, we all came to the same conclusion: we must keep the lessons taught by Dr. Buolamwini within our minds not only in the present, but far into our futures as well. Since technology, artificial intelligence, and other systems will only continue to grow for the rest of our lives, we as programmers, professionals, and consumers of technology must work to better everyone, not just for a select few. Just as Dr. Buolamwini notes, artificial intelligence should not cease to exist, but rather stereotypes and harmful assumptions that are programmed into it should no longer exist. We must continue to strive for a future where the systems we have in place now are more equitable.</p>

<p>Moreover, when creating our teachable machine, we chose to teach our machine three common human emotions, these being happiness, sadness, and anger. These emotions were chosen because, though able to be shown differently person-to-person, overall tend to be universal in a basic form. For many, happiness can be equated with someone smiling, sadness with crying, and anger with furrowed brows and maybe one using an elevated voice. However, as we have learned from Dr. Buolamwini, simply using these emotions based on one person's data can be unhelpful, it would narrow down what our model could recognize. We kept in mind that this is how discriminatory systems are able to be created, and tried to widen our dataset.</p>

<p>Tying this understanding of emotions with our lessons from Dr. Buolamwini, we from the beginning made it our goal for our machine to recognize the aforementioned emotions from multiple groups of people, rather than just one person or one group of people. Programming biases and discrimination into technology is something that is done by humans, and therefore is something that needs to be undone by humans as well, which is why this lesson stood out so much to us when creating our machine.</p>

<p>Our teachable machine is just one drop in the large ocean of technology that has been embedded with racism, biases, and many other forms of discrimination. Despite this, however, through projects like ours, those within our class, and others across universities and companies around the world, our collective fight and learned knowledge of how discrimination is designed within our technology only makes us stronger. We are more aware of how to program out these harmful designs, and how crucial it is for people from all walks of life to be a part of creation and design of technology, especially in regard to artificial intelligence.</p>

<p>It is also important to note that this is a continued process, not a one time fix. Programmers may initially create these biased technologies unintentionally, however the harm they cause is still significant and disproportionately affects marginalized communities. Unmasking AI has taught us that it is crucial to ask how a system or technology thought to be neutral affects all communities. That is why for our project we hope to test and train our model on multiple different faces, and discuss how accurate it is on picking up what emotion is being portrayed. It is important to compare what emotions the machine struggled to pick up, if it was not picking up emotions accurately on a specific person. We also were making note of other smaller factors that could introduce bias into our project as well.</p>

<p>All of this being said, we hope that you enjoy browsing our website and interacting with our teachable machine, and that you are doing everything possible to help artificial intelligence, and technology as a whole, now and into the future become programmed without discrimination and is representative of the world as a whole, not just for a select few.</p>

</div>
</details>
</section>


      <!-- LIMITATIONS -->
      <section>
        <h2>Limitations & Open Questions</h2>
        <ul>
          <li>Best performance on the three creators; may fail on unfamiliar faces</li>
          <li>Lighting and angle strongly affect predictions</li>
          <li>Subtle or complex expressions remain challenging</li>
        </ul>
        <p>The goal is not perfect accuracy but <strong>critical reflection</strong> on how emotion recognition is used in society.</p>
      </section>

    </article>
  </main>


  <!-- FOOTER-->
  <footer class="footer">
    <p>Made by LIS500 Project Group 1 üçà</p>
  </footer>


  <!-- JS file -->
  <script src="tm_emotion.js"></script>
</body>
</html>
